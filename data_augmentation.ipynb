{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ef1813-3de7-4b08-bdf7-ec3e5313b7b9",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7296e38b-1fcb-4778-b73a-b2fb99b7b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ed8819-1496-4c7b-bb39-202f7dff2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress the convergence warning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f0a8b3-e561-4eb0-86a1-dc4b9c67e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = r\"C:\\Users\\sb013698\\Desktop\\github\\Machine Learning in Finance\\Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f62f457-2e71-49be-9adc-0cd931ffff3b",
   "metadata": {},
   "source": [
    "## Detecting Fraudulent Transactions with MLP Models\n",
    "- In this problem, we will focus on predicting whether a transaction is a fraud or not. \n",
    "- All transactions are provided in \"transactions.csv.\" The file contains only numerical input variables resulting from a PCA transformation.\n",
    "- Due to confidentiality issues, original features cannot be provided. Features {V1, V2, …, V28} are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'.\n",
    "- Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\n",
    "- The feature 'Amount' is the transaction Amount. This feature can be used for example-dependent cost-sensitive learning.\n",
    "- Feature 'Class' is the response variable, and it takes value one in case of fraud and zero otherwise.\n",
    "- Since the target feature is imbalanced, we will address this issue using a data augmentation technique known as the Synthetic Minority Oversampling Technique (SMOTE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836a831f-cc45-4c45-a2c4-e0aa6386cd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "transaction_data = pd.read_csv(os.path.join(data_directory, \"transactions.csv\"))\n",
    "print(transaction_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0062927f-d4ab-4bf3-befb-d15c03af529f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13ed4f9-45fd-4dc7-97e6-fb4392d3e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations: Not Fraud = 284315 & Fraud = 492\n",
      "Class ratios (%): Not Fraud = 99.83 & Fraud = 0.17\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution in the target variable\n",
    "n_not_frauds = transaction_data[\"Class\"].value_counts().values[0]\n",
    "n_frauds = transaction_data[\"Class\"].value_counts().values[1]\n",
    "n_data = transaction_data.shape[0]\n",
    "\n",
    "print(f\"Number of observations: Not Fraud = {n_not_frauds} & Fraud = {n_frauds}\")\n",
    "print(f\"Class ratios (%): Not Fraud = {(100*n_not_frauds/n_data):.2f} & Fraud = {(100*n_frauds/n_data):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f86f7-42be-4d72-beac-4fafc6eae6f3",
   "metadata": {},
   "source": [
    "**Note:** Only 0.17% of the entire data is labeled as one (fraud), while the rest of the data is labeled as zero (not fraud). Such an imbalanced distribution complicates learning the patterns that make an observation fraud.\n",
    "- We will now evalute two different MLP architectures with and without applying SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a9b14e-43fc-418a-8734-56c7255c664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "result_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eda6b69-92c3-4e2b-b259-024723f13aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP model with different architectures\n",
    "# Model 1: MLP with 1 hidden layer of 16 units\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Model 2: MLP with 2 hidden layers, 16 units in first layer and 8 units in second layer\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(16, 8), max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ffbed6-b0df-481f-97c7-2fddcca9157f",
   "metadata": {},
   "source": [
    "### Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470bce50-b710-4072-b9a7-a3a3213e5b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (256326, 30)\n",
      "Test shape: (28481, 30)\n",
      "Class distributions\n",
      "Train set: Class\n",
      "0    0.998272\n",
      "1    0.001728\n",
      "Name: proportion, dtype: float64\n",
      "Test set: Class\n",
      "0    0.99828\n",
      "1    0.00172\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = transaction_data.drop('Class', axis=1)\n",
    "y = transaction_data['Class']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42,\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# Print class distribution in train and test sets\n",
    "print(\"Class distributions\")\n",
    "print(f\"Train set: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test set: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b5ede5-f851-4f3e-b5b3-9546de3da16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP1: Perform 5-fold cross-validation and calculate the F1 score\n",
    "mlp1_results = cross_val_score(\n",
    "    mlp1, X_train_scaled, y_train, \n",
    "    cv=5, scoring=make_scorer(f1_score),\n",
    ")\n",
    "# Store the result in result_list\n",
    "result_list.append({\n",
    "    \"Model Name\": \"MLP-1\",\n",
    "    \"IsSMOTEApplied\": \"No\",\n",
    "    \"Hidden Layers\": 1,\n",
    "    \"Hidden Units\": (16,),\n",
    "    \"Average F1-Score\": mlp1_results.mean()\n",
    "})\n",
    "\n",
    "# MLP2: Perform 5-fold cross-validation and calculate the F1 score\n",
    "mlp2_results = cross_val_score(\n",
    "    mlp2, X_train_scaled, y_train, \n",
    "    cv=5, scoring=make_scorer(f1_score),\n",
    ")\n",
    "# Store the result in result_list\n",
    "result_list.append({\n",
    "    \"Model Name\": \"MLP-2\",\n",
    "    \"IsSMOTEApplied\": \"No\",\n",
    "    \"Hidden Layers\": 2,\n",
    "    \"Hidden Units\": (16, 8),\n",
    "    \"Average F1-Score\": mlp2_results.mean()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5dc431-bda6-4c0b-8cf4-1827ba287016",
   "metadata": {},
   "source": [
    "### With SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b8a423-1162-4dbb-a0e7-5b9bc1af217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE\n",
      "Train shape: (256326, 30)\n",
      "Test shape: (28481, 30)\n",
      "Class distributions\n",
      "Train set: Class\n",
      "0    0.998272\n",
      "1    0.001728\n",
      "Name: proportion, dtype: float64\n",
      "Test set: Class\n",
      "0    0.99828\n",
      "1    0.00172\n",
      "Name: proportion, dtype: float64\n",
      "==================================================\n",
      "After SMOTE\n",
      "Train shape: (511766, 30)\n",
      "Test shape: (28481, 30)\n",
      "Class distributions\n",
      "Train set: Class\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "Test set: Class\n",
      "0    0.99828\n",
      "1    0.00172\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = transaction_data.drop('Class', axis=1)\n",
    "y = transaction_data['Class']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y, random_state=42,\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Before SMOTE\")\n",
    "print(f\"Train shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test shape: {X_test_scaled.shape}\")\n",
    "# Print class distribution in train and test sets\n",
    "print(\"Class distributions\")\n",
    "print(f\"Train set: {y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test set: {y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "# Apply SMOTE to balance class distribution (only on training data)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"After SMOTE\")\n",
    "print(f\"Train shape: {X_train_resampled.shape}\")\n",
    "print(f\"Test shape: {X_test_scaled.shape}\")\n",
    "# Print class distribution in train and test sets\n",
    "print(\"Class distributions\")\n",
    "print(f\"Train set: {y_train_resampled.value_counts(normalize=True)}\")\n",
    "print(f\"Test set: {y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a48c39a9-f2f4-4cc4-8dc6-7b56edcf9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP1: Perform 5-fold cross-validation and calculate the F1 score with the augmented data\n",
    "mlp1_smote_results = cross_val_score(\n",
    "    mlp1, X_train_resampled, y_train_resampled, \n",
    "    cv=5, scoring=make_scorer(f1_score),\n",
    ")\n",
    "# Store the result in result_list\n",
    "result_list.append({\n",
    "    \"Model Name\": \"MLP-1\",\n",
    "    \"IsSMOTEApplied\": \"Yes\",\n",
    "    \"Hidden Layers\": 1,\n",
    "    \"Hidden Units\": (16,),\n",
    "    \"Average F1-Score\": mlp1_smote_results.mean()\n",
    "})\n",
    "\n",
    "# MLP2: Perform 5-fold cross-validation and calculate the F1 score with the augmented data\n",
    "mlp2_smote_results = cross_val_score(\n",
    "    mlp2, X_train_resampled, y_train_resampled, \n",
    "    cv=5, scoring=make_scorer(f1_score),\n",
    ")\n",
    "# Store the result in result_list\n",
    "result_list.append({\n",
    "    \"Model Name\": \"MLP-2\",\n",
    "    \"IsSMOTEApplied\": \"Yes\",\n",
    "    \"Hidden Layers\": 2,\n",
    "    \"Hidden Units\": (16, 8),\n",
    "    \"Average F1-Score\": mlp2_smote_results.mean()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f832a60c-41f6-4acd-bc56-55fcfc7cba0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>IsSMOTEApplied</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Hidden Units</th>\n",
       "      <th>Average F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLP-2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.999320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP-1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>(16,)</td>\n",
       "      <td>0.999096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP-1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>(16,)</td>\n",
       "      <td>0.838860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLP-2</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.824226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name IsSMOTEApplied  Hidden Layers Hidden Units  Average F1-Score\n",
       "3      MLP-2            Yes              2      (16, 8)          0.999320\n",
       "2      MLP-1            Yes              1        (16,)          0.999096\n",
       "0      MLP-1             No              1        (16,)          0.838860\n",
       "1      MLP-2             No              2      (16, 8)          0.824226"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print overall results\n",
    "mlp_df = pd.DataFrame(result_list)\n",
    "mlp_df.sort_values(by=\"Average F1-Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7abe18-6f0d-418b-82d7-2c3af73ec338",
   "metadata": {},
   "source": [
    "**Discussion:** The results show that F1 scores are much lower when SMOTE is not used. When SMOTE is applied, the imbalanced target distribution is improved. Hence, the classification is performed correctly for both \"Fraud\" and \"Not Fraud\" classes thanks to increasing the sample size with SMOTE. For example, applying SMOTE increased the F1 score of the MLP-2 model by around 23%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d21fb-6dca-4a12-be72-415c3aa6a91f",
   "metadata": {},
   "source": [
    "## MLP for House Price Prediction\n",
    "\n",
    "Let us now focus on the Real State Price dataset. In this problem, we will implement four MLP models with distinct architectures:\n",
    "\n",
    "    1) MLP with 1 hidden layer with 8 units in hidden layer,\n",
    "\n",
    "    2) MLP with 1 hidden layer with 4 units in hidden layer,\n",
    "\n",
    "    3) MLP with 2 hidden layers with 16 units in first layer and 8 units in the second layer.\n",
    "\n",
    "    4) MLP with 2 hidden layers with 8 units in first layer and 4 units in the second layer.\n",
    "\n",
    "- We will predict house sale price (last column) by using the following attributes:\n",
    "      \\\n",
    "    [\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]\n",
    "\n",
    "- During training, we will tune learning rate and number of epochs.\n",
    "- We will evalute the model's performance by applying 5-fold cross-validation and using R2 score and RMSE for the test evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77393432-97d0-4464-9119-c79a90f43e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    }
   ],
   "source": [
    "house_data = pd.read_csv(os.path.join(data_directory, \"kaggle_house.csv\"))\n",
    "print(house_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b06a7f-1b6b-4b4f-80e7-566698d772c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 10)\n"
     ]
    }
   ],
   "source": [
    "required_columns = [\n",
    "    \"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "    \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\",\n",
    "]\n",
    "house_data = house_data[required_columns].copy()\n",
    "print(house_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eab68df4-4a0a-46e7-be8a-d4fd7009ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SalePrice    1460 non-null   int64  \n",
      " 1   MSSubClass   1460 non-null   int64  \n",
      " 2   MSZoning     1460 non-null   object \n",
      " 3   LotFrontage  1201 non-null   float64\n",
      " 4   LotArea      1460 non-null   int64  \n",
      " 5   Street       1460 non-null   object \n",
      " 6   YearBuilt    1460 non-null   int64  \n",
      " 7   LotShape     1460 non-null   object \n",
      " 8   1stFlrSF     1460 non-null   int64  \n",
      " 9   2ndFlrSF     1460 non-null   int64  \n",
      "dtypes: float64(1), int64(6), object(3)\n",
      "memory usage: 114.2+ KB\n"
     ]
    }
   ],
   "source": [
    "house_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2b79fb-f1b9-4401-9508-788ea7f11d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice        0\n",
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage    259\n",
       "LotArea          0\n",
       "Street           0\n",
       "YearBuilt        0\n",
       "LotShape         0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing entries\n",
    "house_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f95ddb4-b98d-401c-9876-88bc7e2ee26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice      0\n",
       "MSSubClass     0\n",
       "MSZoning       0\n",
       "LotFrontage    0\n",
       "LotArea        0\n",
       "Street         0\n",
       "YearBuilt      0\n",
       "LotShape       0\n",
       "1stFlrSF       0\n",
       "2ndFlrSF       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing instances in the \"LotShape\" feature\n",
    "house_data = house_data.dropna()\n",
    "\n",
    "# Check for missing entries once more\n",
    "house_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d6f265e-e982-4463-a77e-20e16a504844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1080, 17)\n",
      "Test shape: (121, 17)\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = house_data.drop(columns=\"SalePrice\", axis=1)\n",
    "y = house_data[\"SalePrice\"].values\n",
    "\n",
    "# Apply one-hot-encoding to the categorical features\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "472acb67-f951-4b49-b0d6-9c46846b26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for hyperparameter tuning\n",
    "def find_best(X_train, y_train, X_test, y_test, model_name):\n",
    "\n",
    "    # Define the base models\n",
    "    models = {\n",
    "        \"model1\": MLPRegressor(hidden_layer_sizes=(8,), random_state=42),\n",
    "        \"model2\": MLPRegressor(hidden_layer_sizes=(4,), random_state=42),\n",
    "        \"model3\": MLPRegressor(hidden_layer_sizes=(16, 8), random_state=42),\n",
    "        \"model4\": MLPRegressor(hidden_layer_sizes=(8, 4), random_state=42),\n",
    "    }\n",
    "\n",
    "    # Ensure the specified model is valid\n",
    "    if model_name not in models:\n",
    "        raise ValueError(f\"Invalid model name '{model_name}'. Choose from 'model1', 'model2', 'model3', 'model4'.\")\n",
    "\n",
    "    # Get the specified model\n",
    "    model = models[model_name]\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        \"learning_rate_init\": [1e-3, 5e-3, 1e-2],\n",
    "        \"max_iter\": [250, 500, 750, 1000, 2000],\n",
    "    }\n",
    "\n",
    "    # Define scoring metric (negative MSE)\n",
    "    scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring=scoring, verbose=0)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the optimal hyperparameters\n",
    "    best_lr = grid_search.best_params_[\"learning_rate_init\"]\n",
    "    best_epoch = grid_search.best_params_[\"max_iter\"]\n",
    "\n",
    "    # Re-train the model using optimal hyperparameters\n",
    "    optimized_model = MLPRegressor(\n",
    "        hidden_layer_sizes=model.hidden_layer_sizes,\n",
    "        learning_rate_init=best_lr,\n",
    "        max_iter=best_epoch,\n",
    "        random_state=42,\n",
    "    )\n",
    "    optimized_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the best model's performance on the test set\n",
    "    test_preds = optimized_model.predict(X_test)\n",
    "    r2 = r2_score(y_test, test_preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    mape = mean_absolute_percentage_error(y_test, test_preds)\n",
    "\n",
    "    # Create a dictionary for the model's test results\n",
    "    model_results = {\n",
    "        \"Model Name\": model_name,\n",
    "        \"Hidden Layer Sizes\": model.hidden_layer_sizes,\n",
    "        \"Learning Rate\": best_lr,\n",
    "        \"Number of Epochs\": best_epoch,\n",
    "        \"Test R2-Score\": r2,\n",
    "        \"Test RMSE\": rmse,\n",
    "        \"Test MAPE\": mape,\n",
    "    }\n",
    "\n",
    "    return optimized_model, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64bd79fc-d314-409d-b30f-467109b0dc3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store model results\n",
    "result_list = list()\n",
    "\n",
    "# Model-1\n",
    "best_model1, model1_results = find_best(\n",
    "    X_train_scaled, y_train,\n",
    "    X_test_scaled, y_test,\n",
    "    model_name=\"model1\",\n",
    ")\n",
    "result_list.append(model1_results)\n",
    "\n",
    "# Model-2\n",
    "best_model2, model2_results = find_best(\n",
    "    X_train_scaled, y_train,\n",
    "    X_test_scaled, y_test,\n",
    "    model_name=\"model2\",\n",
    ")\n",
    "result_list.append(model2_results)\n",
    "\n",
    "# Model-3\n",
    "best_model3, model3_results = find_best(\n",
    "    X_train_scaled, y_train,\n",
    "    X_test_scaled, y_test,\n",
    "    model_name=\"model3\",\n",
    ")\n",
    "result_list.append(model3_results)\n",
    "\n",
    "# Model-4\n",
    "best_model4, model4_results = find_best(\n",
    "    X_train_scaled, y_train,\n",
    "    X_test_scaled, y_test,\n",
    "    model_name=\"model4\",\n",
    ")\n",
    "result_list.append(model4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44632198-c202-41f3-88dc-20f4ffebec61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Hidden Layer Sizes</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Number of Epochs</th>\n",
       "      <th>Test R2-Score</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model4</td>\n",
       "      <td>(8, 4)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.793355</td>\n",
       "      <td>46737.749886</td>\n",
       "      <td>0.175086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model3</td>\n",
       "      <td>(16, 8)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.789654</td>\n",
       "      <td>47154.469023</td>\n",
       "      <td>0.189969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1</td>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.562443</td>\n",
       "      <td>68009.936014</td>\n",
       "      <td>0.227756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model2</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>102410.525670</td>\n",
       "      <td>0.428317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name Hidden Layer Sizes  Learning Rate  Number of Epochs  \\\n",
       "3     model4             (8, 4)          0.010              2000   \n",
       "2     model3            (16, 8)          0.005              2000   \n",
       "0     model1               (8,)          0.010              2000   \n",
       "1     model2               (4,)          0.010              2000   \n",
       "\n",
       "   Test R2-Score      Test RMSE  Test MAPE  \n",
       "3       0.793355   46737.749886   0.175086  \n",
       "2       0.789654   47154.469023   0.189969  \n",
       "0       0.562443   68009.936014   0.227756  \n",
       "1       0.007847  102410.525670   0.428317  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_df = pd.DataFrame(result_list)\n",
    "regression_df.sort_values(by=\"Test RMSE\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a9538d0-1f50-426e-99be-4e104f53ea45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(8, 4), learning_rate_init=0.01, max_iter=2000,\n",
       "             random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(8, 4), learning_rate_init=0.01, max_iter=2000,\n",
       "             random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(8, 4), learning_rate_init=0.01, max_iter=2000,\n",
       "             random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the best model with optimal hp values\n",
    "final_model = MLPRegressor(\n",
    "    hidden_layer_sizes=(8, 4),\n",
    "    learning_rate_init=1e-2,\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e464e1a-b48b-45b0-ab53-4f05bdb235cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c879e0c-4ee0-4a72-b055-ef2368cf040d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eae4d96-e0a8-4ca5-b9df-5c611f9c44bb",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

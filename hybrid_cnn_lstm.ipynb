{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3c8369-e9ea-4b3a-b227-aed1050a85ee",
   "metadata": {},
   "source": [
    "# CNN-LSTM for Predicting Household Power Consumption\n",
    "- In this problem, we will use a combined architecture of CNN and LSTM to predict household power consumption from historical power consumption.\n",
    "- The data is provided in the \"household_power_consumption.txt\" file.\n",
    "- In this dataset, one household's electric power consumption measurements have a one-minute sampling rate over almost 4 years.\n",
    "- Unlike single-time step prediction, we are now interested in predicting 60-time points (1 hour) from 600-time points (10 hours).\n",
    "- Note that we must carefully tune the learning rate and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6bc1117-28ad-4b11-a005-ab11bb6e91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94fd38e-984b-43b8-b985-322efebd2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = r\"C:\\Users\\said_\\OneDrive\\Masaüstü\\github\\Machine Learning in Finance\\Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6fe02e2-c042-4730-a12b-60acd49f5da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2075259, 9)\n"
     ]
    }
   ],
   "source": [
    "file_name = os.path.join(data_directory, \"household_power_consumption.txt\")\n",
    "power_df = pd.read_csv(file_name, sep=';', low_memory=False, na_values=['?'])\n",
    "print(power_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d1fa64d-1c38-46e6-83ff-ef2ce430d25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  Global_active_power  Global_reactive_power  Voltage  \\\n",
       "0  16/12/2006  17:24:00                4.216                  0.418   234.84   \n",
       "1  16/12/2006  17:25:00                5.360                  0.436   233.63   \n",
       "2  16/12/2006  17:26:00                5.374                  0.498   233.29   \n",
       "3  16/12/2006  17:27:00                5.388                  0.502   233.74   \n",
       "4  16/12/2006  17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "0              18.4             0.0             1.0            17.0  \n",
       "1              23.0             0.0             1.0            16.0  \n",
       "2              23.0             0.0             2.0            17.0  \n",
       "3              23.0             0.0             1.0            17.0  \n",
       "4              15.8             0.0             1.0            17.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260a7670-1136-4085-afbf-fb0c9f61ab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Day: 31\n",
      "Length of Month: 12\n",
      "Length of Year: 5\n",
      "Length of Hour: 24\n",
      "Length of Minute: 60\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "power_df['Date'] = pd.to_datetime(power_df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Create day, month, and year columns\n",
    "power_df['Day'] = power_df['Date'].dt.day\n",
    "power_df['Month'] = power_df['Date'].dt.month\n",
    "power_df['Year'] = power_df['Date'].dt.year\n",
    "\n",
    "# Convert the 'Time' column to datetime\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'], format='%H:%M:%S')\n",
    "\n",
    "# Extract hours and minutes\n",
    "power_df['Hour'] = power_df['Time'].dt.hour\n",
    "power_df['Minute'] = power_df['Time'].dt.minute\n",
    "\n",
    "# Check if the time extraction is proper\n",
    "for c in [\"Day\", \"Month\", \"Year\", \"Hour\", \"Minute\"]:\n",
    "    date_indices = power_df[c].value_counts().index.to_list()\n",
    "    print(f\"Length of {c}: {len(date_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f30bb30-2ca1-4a6b-aae3-700a95691e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                         0\n",
      "Time                         0\n",
      "Global_active_power      25979\n",
      "Global_reactive_power    25979\n",
      "Voltage                  25979\n",
      "Global_intensity         25979\n",
      "Sub_metering_1           25979\n",
      "Sub_metering_2           25979\n",
      "Sub_metering_3           25979\n",
      "Day                          0\n",
      "Month                        0\n",
      "Year                         0\n",
      "Hour                         0\n",
      "Minute                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(power_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273ba73d-f526-4957-bd5d-56b71598255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                     0\n",
      "Time                     0\n",
      "Global_active_power      0\n",
      "Global_reactive_power    0\n",
      "Voltage                  0\n",
      "Global_intensity         0\n",
      "Sub_metering_1           0\n",
      "Sub_metering_2           0\n",
      "Sub_metering_3           0\n",
      "Day                      0\n",
      "Month                    0\n",
      "Year                     0\n",
      "Hour                     0\n",
      "Minute                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values using forward fill\n",
    "power_df = power_df.ffill()\n",
    "# If there are still NaN values (e.g., at the start of the series), optionally use backward fill\n",
    "power_df = power_df.bfill()\n",
    "# Check for missing values once more\n",
    "print(power_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308c7988-eb35-4dc9-9a0a-f75025b1363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2075259, 10)\n"
     ]
    }
   ],
   "source": [
    "# Re-order the data columns as target + features\n",
    "target = ['Global_active_power']\n",
    "main_features = [\n",
    "    'Global_reactive_power', 'Voltage', 'Global_intensity', \n",
    "    'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3', \n",
    "]\n",
    "# Do not include some date time features\n",
    "time_features = ['Month', 'Day', 'Hour']\n",
    "# Make sure the target is the first column\n",
    "column_order = target + main_features + time_features\n",
    "final_df = power_df[column_order].copy()\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26711d85-1bd2-4328-8a18-974c010ec379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Global_active_power  Global_reactive_power  Voltage  Global_intensity  \\\n",
       "0                4.216                  0.418   234.84              18.4   \n",
       "1                5.360                  0.436   233.63              23.0   \n",
       "2                5.374                  0.498   233.29              23.0   \n",
       "3                5.388                  0.502   233.74              23.0   \n",
       "4                3.666                  0.528   235.68              15.8   \n",
       "\n",
       "   Sub_metering_1  Sub_metering_2  Sub_metering_3  Month  Day  Hour  \n",
       "0             0.0             1.0            17.0     12   16    17  \n",
       "1             0.0             1.0            16.0     12   16    17  \n",
       "2             0.0             2.0            17.0     12   16    17  \n",
       "3             0.0             1.0            17.0     12   16    17  \n",
       "4             0.0             1.0            17.0     12   16    17  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1c8a198-e272-47e0-925f-ee48f0d9f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2075259, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "new_df = final_df.copy()\n",
    "# Specify the column to be excluded from scaling\n",
    "column_not_scaled = 'Global_active_power'\n",
    "# Select only the numeric columns (exclude any non-numeric ones)\n",
    "numeric_columns = new_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Exclude the target column ('Earnings Per Share') from scaling\n",
    "columns_to_scale = [col for col in numeric_columns if col != column_not_scaled]\n",
    "# Extract the subset of the numeric columns to scale\n",
    "subset_to_scale = new_df[columns_to_scale]\n",
    "# Initialize and fit the scaler on the subset\n",
    "scaler = StandardScaler()\n",
    "scaled_subset = scaler.fit_transform(subset_to_scale)\n",
    "# Replace the original values with scaled values in the DataFrame\n",
    "new_df[columns_to_scale] = scaled_subset\n",
    "print(new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8324b3c-1164-4b51-8bb4-e67ea47fa2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.216</td>\n",
       "      <td>2.618973</td>\n",
       "      <td>-1.854882</td>\n",
       "      <td>3.116440</td>\n",
       "      <td>-0.181657</td>\n",
       "      <td>-0.049761</td>\n",
       "      <td>1.257014</td>\n",
       "      <td>1.624716</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.794432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.360</td>\n",
       "      <td>2.778952</td>\n",
       "      <td>-2.228850</td>\n",
       "      <td>4.155571</td>\n",
       "      <td>-0.181657</td>\n",
       "      <td>-0.049761</td>\n",
       "      <td>1.138242</td>\n",
       "      <td>1.624716</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.794432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.374</td>\n",
       "      <td>3.329993</td>\n",
       "      <td>-2.333932</td>\n",
       "      <td>4.155571</td>\n",
       "      <td>-0.181657</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>1.257014</td>\n",
       "      <td>1.624716</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.794432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.388</td>\n",
       "      <td>3.365544</td>\n",
       "      <td>-2.194853</td>\n",
       "      <td>4.155571</td>\n",
       "      <td>-0.181657</td>\n",
       "      <td>-0.049761</td>\n",
       "      <td>1.257014</td>\n",
       "      <td>1.624716</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.794432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.666</td>\n",
       "      <td>3.596626</td>\n",
       "      <td>-1.595268</td>\n",
       "      <td>2.529104</td>\n",
       "      <td>-0.181657</td>\n",
       "      <td>-0.049761</td>\n",
       "      <td>1.257014</td>\n",
       "      <td>1.624716</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>0.794432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Global_active_power  Global_reactive_power   Voltage  Global_intensity  \\\n",
       "0                4.216               2.618973 -1.854882          3.116440   \n",
       "1                5.360               2.778952 -2.228850          4.155571   \n",
       "2                5.374               3.329993 -2.333932          4.155571   \n",
       "3                5.388               3.365544 -2.194853          4.155571   \n",
       "4                3.666               3.596626 -1.595268          2.529104   \n",
       "\n",
       "   Sub_metering_1  Sub_metering_2  Sub_metering_3     Month       Day  \\\n",
       "0       -0.181657       -0.049761        1.257014  1.624716  0.025759   \n",
       "1       -0.181657       -0.049761        1.138242  1.624716  0.025759   \n",
       "2       -0.181657        0.123044        1.257014  1.624716  0.025759   \n",
       "3       -0.181657       -0.049761        1.257014  1.624716  0.025759   \n",
       "4       -0.181657       -0.049761        1.257014  1.624716  0.025759   \n",
       "\n",
       "       Hour  \n",
       "0  0.794432  \n",
       "1  0.794432  \n",
       "2  0.794432  \n",
       "3  0.794432  \n",
       "4  0.794432  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d145e39-0b65-4490-8147-bd7043f7d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "sequences = list()\n",
    "targets = list()\n",
    "\n",
    "# Define a sequence and output lengths in minutes\n",
    "# Sequence length: 600 mins (10 hours)\n",
    "sequence_length = 600\n",
    "# Predicting the next 60 time points (1 hour)\n",
    "output_length = 60\n",
    "\n",
    "for i in range(len(new_df) - sequence_length - output_length + 1):\n",
    "    # Create sequence of 600 time points as input features\n",
    "    seq_features = new_df.iloc[i:(i + sequence_length)].values\n",
    "    # Create target sequence of 60 time points (next 60 time steps)\n",
    "    seq_target = new_df.iloc[(i + sequence_length):(i + sequence_length + output_length), 0].values\n",
    "    \n",
    "    sequences.append(seq_features)\n",
    "    targets.append(seq_target)\n",
    "\n",
    "# Convert sequences and targets to numpy arrays\n",
    "X = np.array(sequences, dtype=np.float32)\n",
    "y = np.array(targets, dtype=np.float32)\n",
    "\n",
    "print(f\"Sequence shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049232f2-cf71-4616-92a3-afa2ae11eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sequences and target for future use\n",
    "np.save(os.path.join(data_directory, 'power_sequences.npy'), X)\n",
    "np.save(os.path.join(data_directory, 'power_targets.npy'), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcffa00-c01c-4977-8ae6-411e1ba2aa6b",
   "metadata": {},
   "source": [
    "## Model Development: CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a70484-7c55-4ec3-aa6c-ed7a49ecb1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shape: (2074600, 600, 10)\n",
      "Target shape: (2074600, 60)\n"
     ]
    }
   ],
   "source": [
    "# Load sequences and targets\n",
    "X = np.load(os.path.join(data_directory, 'power_sequences.npy'))\n",
    "y = np.load(os.path.join(data_directory, 'power_targets.npy'))\n",
    "\n",
    "print(f\"Sequence shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "416b717b-5889-4957-b3e3-741b296331e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 598, 64)           1984      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 299, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 297, 128)          24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 148, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               7800      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                7260      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,156\n",
      "Trainable params: 91,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define a hybrid architecture\n",
    "model = Sequential()\n",
    "\n",
    "# CNN layers for feature extraction\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(600, 10)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# LSTM layers for capturing temporal dependencies\n",
    "model.add(LSTM(units=64, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully connected layers for prediction\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(60))  # Output layer for the next 60 time steps\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86affee7-ad40-4223-b3c8-97f8ec8a08fa",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f034ec-223d-4fe1-b2d7-bf38caa4d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test split\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=(val_size + test_size), random_state=42,\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=(test_size / (val_size + test_size)), random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Validation shape: {X_val.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854f195-667d-44cc-8417-fa11e12be01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scenarios for hyperparameter tuning\n",
    "lr_list = [1e-3, 5e-3, 1e-2]\n",
    "epoch_list = [5, 10, 15, 20]\n",
    "\n",
    "# Generate all combinations of learning rate and epochs\n",
    "power_combinations = list(itertools.product(lr_list, epoch_list))\n",
    "print(f\"Number of combinations: {len(power_combinations)}\")\n",
    "print(power_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e7a90-4297-4c32-aea9-8d55e7c432f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the results file already exists\n",
    "results_file = os.path.join(data_directory, \"hp_results_power.csv\")\n",
    "\n",
    "# Initialize an empty dataframe if the file doesn't exist\n",
    "if os.path.exists(results_file):\n",
    "    # Load existing results if the file exists\n",
    "    results_df = pd.read_csv(results_file)\n",
    "else:\n",
    "    # Create an empty df to store results\n",
    "    results_df = pd.DataFrame(columns=[\"Scenario\", \"Learning Rate\", \"Number of Epochs\", \"MAPE\"])\n",
    "\n",
    "scenario_id = 1\n",
    "\n",
    "for combo in tqdm(power_combinations):\n",
    "\n",
    "    # Define parameter values from combinations\n",
    "    lr, epoch = combo\n",
    "\n",
    "    # Compile the model with the given hyperparameters\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "    # Define EarlyStopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    ) \n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val), # Calculate val_loss for early stopping\n",
    "        epochs=epoch, \n",
    "        batch_size=2560, \n",
    "        verbose=0, \n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    # Make predictions over the validation set and evaluate model's performance using MAPE\n",
    "    preds = model.predict(X_val, verbose=0)\n",
    "    mape = mean_absolute_percentage_error(y_val, preds)\n",
    "\n",
    "    # Store scenario results in a dictionary\n",
    "    result = {\n",
    "        \"Scenario\": f\"S{scenario_id}\",\n",
    "        \"Learning Rate\": lr,\n",
    "        \"Number of Epochs\": epoch,\n",
    "        \"MAPE\": mape,\n",
    "    }\n",
    "\n",
    "    scenario_id += 1\n",
    "\n",
    "    # Convert the result to a DataFrame\n",
    "    scenario_result = pd.DataFrame([result])\n",
    "\n",
    "    # Concatenate the new result with the existing DataFrame\n",
    "    if results_df.empty:\n",
    "        results_df = scenario_result\n",
    "    else:\n",
    "        results_df = pd.concat([results_df, scenario_result], ignore_index=True)\n",
    "\n",
    "    # Save results to CSV after each scenario\n",
    "    results_df.to_csv(results_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867207b-92df-48f0-a9a0-09341adfd89d",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af1bcc39-bc98-4d32-b247-a6878831fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training sequences: (1867140, 600, 10)\n",
      "Shape of test sequences: (207460, 600, 10)\n"
     ]
    }
   ],
   "source": [
    "# Use 90% of data for training and 10% for testing\n",
    "test_size = 0.1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Shape of training sequences: {X_train.shape}\")\n",
    "print(f\"Shape of test sequences: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9ede83-eff8-43ab-8aaa-6af6d49e7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "730/730 [==============================] - 3806s 5s/step - loss: 0.4171 - mae: 0.4171\n",
      "Epoch 2/10\n",
      "730/730 [==============================] - 3375s 5s/step - loss: 0.3853 - mae: 0.3853\n",
      "Epoch 3/10\n",
      "730/730 [==============================] - 3355s 5s/step - loss: 0.3732 - mae: 0.3732\n",
      "Epoch 4/10\n",
      "730/730 [==============================] - 2964s 4s/step - loss: 0.3632 - mae: 0.3632\n",
      "Epoch 5/10\n",
      "730/730 [==============================] - 3374s 5s/step - loss: 0.3543 - mae: 0.3543\n",
      "Epoch 6/10\n",
      "730/730 [==============================] - 3554s 5s/step - loss: 0.3463 - mae: 0.3463\n",
      "Epoch 7/10\n",
      "730/730 [==============================] - 3594s 5s/step - loss: 0.3405 - mae: 0.3405\n",
      "Epoch 8/10\n",
      "730/730 [==============================] - 3572s 5s/step - loss: 0.3364 - mae: 0.3364\n",
      "Epoch 9/10\n",
      "730/730 [==============================] - 3590s 5s/step - loss: 0.3327 - mae: 0.3327\n",
      "Epoch 10/10\n",
      "730/730 [==============================] - 3571s 5s/step - loss: 0.3309 - mae: 0.3309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c52c5ed8e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model with the given hyperparameters\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-3), \n",
    "    loss=\"mae\", \n",
    "    metrics=[\"mae\"],\n",
    ") \n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=10, \n",
    "    batch_size=2560, \n",
    "    verbose=1, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84654d91-72b3-4c92-b4a6-1cabcf461420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6484/6484 [==============================] - 229s 35ms/step\n",
      "{'Test MAPE': 0.3501448631286621, 'Test MSE': 0.37731996178627014, 'Test R2': 0.6575421094894409}\n"
     ]
    }
   ],
   "source": [
    "# Make predictions over the validation set and evaluate model's performance using MAPE\n",
    "test_preds = model.predict(X_test, verbose=1)\n",
    "mape = mean_absolute_percentage_error(y_test, test_preds)\n",
    "mse = mean_squared_error(y_test, test_preds)\n",
    "r2 = r2_score(y_test, test_preds)\n",
    "\n",
    "# Store test results in a dictionary\n",
    "test_result = {\n",
    "    \"Test MAPE\": mape,\n",
    "    \"Test MSE\": mse,\n",
    "    \"Test R2\": r2,\n",
    "}\n",
    "\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24b8379f-1292-4c6a-862e-ef4b0901a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test results as a JSON file\n",
    "# Define a custom function to handle numpy types\n",
    "def handle_numpy_types(obj):\n",
    "    if isinstance(obj, np.float32):\n",
    "        return float(obj)  # Convert numpy.float32 to Python float\n",
    "    raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
    "\n",
    "# Save the dictionary as a JSON file with the custom handler\n",
    "output_file = \"test_result.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(test_result, f, indent=4, default=handle_numpy_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defd2b6-6615-4066-9845-c788bcad6847",
   "metadata": {},
   "source": [
    "**Discussion:** A large amount of training data hindered extensive hyperparameter tuning, which resulted in low regression accuracy with a MAPE of approximately 35%. Adjusting the architecture of the hybrid CNN-LSTM model and experimenting with different combinations of learning rates and epoch numbers could improve the regression performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972ec82b-295d-4853-9a98-08c128561a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2134b-f3f4-4c07-8e12-00ef1a39a55a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d3511e4-f11f-471f-9d3b-2980b03e8df0",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
